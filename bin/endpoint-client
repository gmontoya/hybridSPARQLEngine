#!/usr/bin/env node

var SparqlEndpointIterator2 = require('../lib/hybridTPF/SparqlEndpointIterator2');
var ArrayToElementsIterator = require('../lib/hybridTPF/ArrayToElementsIterator');
var ldf = require('../hybridTPF-client');

// Retrieve and check arguments
var args = require('minimist')(process.argv.slice(2));
if (args.listformats)
  return Object.keys(ldf.SparqlResultWriter.writers).forEach(function (t) { console.log(t); });

if (!args.q && args._.length < 1 || args._.length > 2 || args.h || args.help) {
  console.error('usage: endpoint-client query.sparql ' +
                                          '[-t application/json] [-l logLevel] [--help]' +
                                          '[--endpointUrl z]' );
  console.error('       endpoint-client --listformats (Lists supported result formats for -t)');
  return process.exit(1);
}

// Load main libraries (postponed as to here for speed)
var fs = require('fs'),
    path = require('path'),
    N3 = require('n3'),
    Logger = ldf.Logger
    SparqlParser = require('sparqljs').Parser;

// Parse and initialize configuration
var configFile = args.c ? args.c : path.join(__dirname, '../config-default.json'),
    config = JSON.parse(fs.readFileSync(configFile, { encoding: 'utf8' })),
    queryFile = args.f || args.q || args._.pop(),
    startFragment = args._.pop() || config.startFragment,
    queryText = args.q || (args.f || fs.existsSync(queryFile) ? fs.readFileSync(queryFile, 'utf8') : queryFile),
    mimeType = args.t || 'application/json';

// Added for the hybrid SPARQL engine
config.threshold = args.threshold ? args.threshold : (config.threshold ? config.threshold : 100);
config.endpointUrl = args.endpointUrl ? args.endpointUrl : (config.endpointUrl ? config.endpointUrl : 'http://172.19.2.100:8891/sparql?default-graph-uri=http%3A%2F%2Fdbpedia&query=');
config.maxNumberOfMappings = args.maxNumberOfMappings ? args.maxNumberOfMappings : (config.maxNumberOfMappings ? config.maxNumberOfMappings : 10)

// Configure logging
Logger.setLevel(args.l || 'warning');
var startIterator = Iterator.single({});
config.fragmentsClient = new ldf.FragmentsClient(startFragment, config);
try {
    var sei = new SparqlEndpointIterator2(startIterator, queryText, config.maxNumberOfMappings, config);
    var iter = new ArrayToElementsIterator(sei, config); 
    var writer = new ldf.SparqlResultWriter(mimeType, iter);
    writer.on('data', function (data) { process.stdout.write(data); });
}
// Report a synchronous error
catch (error) {
  console.error('ERROR: Query execution could not start.\n');
  switch (error.name) {
  case 'InvalidQueryError':
  case 'UnsupportedQueryError':
    console.error(error.message);
    break;
  default:
    console.error(error.stack);
  }
}
